setwd("/home/coderus/Temp/git/stability-predictive-monitoring/lstm/results/evaluation_results/")
result_files <- list.files(".", "bpic2012|bpic2017|hospital_billing_3|traffic_fines_1|production|sepsis")
result_files <- result_files[!grepl("complete", result_files)]
result_files <- result_files[!grepl("sample", result_files)]
remove_prefix_nr_from_caseid <- function(row) {
case_id <- row["case_id"]
parts <- strsplit(case_id, "_")[[1]]
cut_length <- ifelse(as.numeric(row["nr_events"]) < 2, length(parts), length(parts)-1)
return(paste(parts[1:cut_length], collapse="_"))
}
data <- data.frame()
for (filename in result_files) {
tmp <- read.table(filename, sep=";", header=T, na.strings=c("None"))
if (!grepl("lstm", filename)) {
tmp$case_id <- as.character(tmp$case_id)
tmp$nr_events <- as.numeric(as.character(tmp$nr_events))
tmp$case_id <- apply(tmp, 1, remove_prefix_nr_from_caseid)
}
data <- rbind(data, tmp)
}
data <- subset(data, dataset != "sepsis_cases_3")
data <- subset(data, params != "cluster_laststate")
data$nr_events <- as.factor(data$nr_events)
data$params <- as.character(data$params)
data[data$params=="pd_fixed_trainratio80_outcome_all_data_singletask", "params"] <- "lstm"
data[data$params=="pd_fixed_trainratio80_outcome_all_data_singletask_timedistributed", "params"] <- "lstm_seq2seq"
data[data$params=="lstm_final", "params"] <- "lstm"
head(data)
nrow(data)
# ROC
library(pROC)
library(plyr)
dt_aucs <- ddply(data, .(dataset, nr_events, params, cls), summarize, count=length(actual), auc=ifelse(length(unique(actual)) < 2, NA, auc(roc(actual, predicted))))
head(dt_aucs)
# stability
setwd("/home/coderus/Temp/git/stability-predictive-monitoring/lstm/results/evaluation_results_detailed//")
result_files <- list.files(".", "bpic2012|bpic2017|hospital_billing_3|traffic_fines_1|production|sepsis")
result_files <- result_files[!grepl("complete", result_files)]
result_files <- result_files[!grepl("sample", result_files)]
remove_prefix_nr_from_caseid <- function(row) {
case_id <- row["case_id"]
parts <- strsplit(case_id, "_")[[1]]
cut_length <- ifelse(as.numeric(row["nr_events"]) < 2, length(parts), length(parts)-1)
return(paste(parts[1:cut_length], collapse="_"))
}
data <- data.frame()
for (filename in result_files) {
tmp <- read.table(filename, sep=";", header=T, na.strings=c("None"))
if (!grepl("lstm", filename)) {
tmp$case_id <- as.character(tmp$case_id)
tmp$nr_events <- as.numeric(as.character(tmp$nr_events))
tmp$case_id <- apply(tmp, 1, remove_prefix_nr_from_caseid)
}
data <- rbind(data, tmp)
}
data <- subset(data, dataset != "sepsis_cases_3")
data <- subset(data, params != "cluster_laststate")
data$nr_events <- as.factor(data$nr_events)
data$params <- as.character(data$params)
data[data$params=="pd_fixed_trainratio80_outcome_all_data_singletask", "params"] <- "lstm"
data[data$params=="pd_fixed_trainratio80_outcome_all_data_singletask_timedistributed", "params"] <- "lstm_seq2seq"
data[data$params=="lstm_final", "params"] <- "lstm"
head(data)
nrow(data)
# ROC
library(pROC)
library(plyr)
dt_aucs <- ddply(data, .(dataset, nr_events, params, cls), summarize, count=length(actual), auc=ifelse(length(unique(actual)) < 2, NA, auc(roc(actual, predicted))))
write.table(dt_aucs, "../stability_analysis/aucs_orig.csv", sep=";", row.names=FALSE, col.names=TRUE)
head(dt_aucs)
nrow(dt_aucs)
ggplot(dt_aucs, aes(x=as.numeric(nr_events), y=auc, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
# stability
dt_stability_cases <- ddply(data, .(dataset, params, cls, case_id), summarize, std=sd(diff(predicted)))
dt_stability_cases <- dt_stability_cases[!is.na(dt_stability_cases),]
dt_stability <- ddply(dt_stability_cases, .(dataset, params, cls), summarize, mean_std=mean(std, na.rm=TRUE), std_std=sd(std, na.rm=TRUE))
#dt_stability <- dt_stability[!is.na(dt_stability),]
dt_stability <- dt_stability[1:nrow(dt_stability)-1,]
write.table(dt_stability, "../stability_analysis/instability_orig.csv", sep=";", row.names=FALSE, col.names=TRUE)
ggplot(dt_stability, aes(x=factor(params), y=mean_std, fill=params, group=params)) + geom_bar(stat="identity") + theme_bw() + facet_wrap(~dataset, scales="free")
# exponential smoothing
tmp <- subset(data, grepl("Application_1000386745", case_id) & cls=="rf" & params=="prefix_index" & dataset=="bpic2017_accepted")
tmp
data$nr_events <- as.numeric(data$nr_events)
betas = c(0.1, 0.25, 0.5, 0.75, 0.9)
datasets <- unique(data$dataset)
#betas <- c(0.1)
#datasets <- c("production")
for (beta in betas) {
print(beta)
for (ds in datasets) {
print(ds)
dt_selected <- subset(data, dataset==ds)
smoothed_preds = subset(dt_selected, nr_events == 1)
smoothed_preds$smoothed_pred <- smoothed_preds$predicted
smoothed_pred_aucs <- ddply(smoothed_preds, .(dataset, nr_events, params, cls), summarize, auc=ifelse(length(unique(actual)) < 2, NA, auc(roc(actual, smoothed_pred))))
for (i in (min(dt_selected$nr_events)+1):max(dt_selected$nr_events)) {
tmp <- subset(dt_selected, nr_events == i)
tmp <- merge(tmp, smoothed_preds[smoothed_preds$nr_events==i-1,c("case_id", "smoothed_pred", "params")], by=c("case_id", "params"))
tmp$smoothed_pred = beta*tmp$smoothed_pred + (1-beta)*tmp$predicted
#tmp$smoothed_pred = tmp$smoothed_pred / (1-beta^i)
#roc_obj <- roc(tmp$actual, tmp$smoothed_pred)
#dt_auc <- ddply(tmp, .(dataset, nr_events, params, cls), summarize, auc=ifelse(length(unique(actual)) < 2, NA, auc(roc(actual, smoothed_pred))))
#dt_auc <- data.frame(auc=auc(roc_obj), nr_events=i, prediction_method=paste("smoothed", beta, sep=""))
#smoothed_pred_aucs <- rbind(smoothed_pred_aucs, dt_auc)
smoothed_preds <- rbind(smoothed_preds, tmp)
}
dt_aucs <- ddply(smoothed_preds, .(dataset, nr_events, params, cls), summarize, count=length(actual), auc=ifelse(length(unique(actual)) < 2, NA, auc(roc(actual, smoothed_pred))))
write.table(dt_aucs, sprintf("../stability_analysis/aucs_%s_%s.csv", ds, beta), sep=";", row.names=FALSE, col.names=TRUE)
dt_stability_cases <- ddply(smoothed_preds, .(dataset, params, cls, case_id), summarize, std=sd(diff(smoothed_pred)))
dt_stability_cases <- dt_stability_cases[!is.na(dt_stability_cases),]
dt_stability <- ddply(dt_stability_cases, .(dataset, params, cls), summarize, mean_std=mean(std, na.rm=TRUE), std_std=sd(std, na.rm=TRUE))
dt_stability <- dt_stability[1:nrow(dt_stability)-1,]
write.table(dt_stability, sprintf("../stability_analysis/instability_%s_%s.csv", ds, beta), sep=";", row.names=FALSE, col.names=TRUE)
}
}
dt_aucs <- read.table("../stability_analysis/aucs_orig.csv", sep=";", header=T)
dt_aucs
head(dt_aucs)
png("../stability_analysis/aucs_orig.png", width=1300, height=900)
ggplot(dt_aucs, aes(x=as.numeric(nr_events), y=auc, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
dev.off()
dt_stability <- read.table("../stability_analysis/instability_orig.csv", sep=";", header=T)
head(dt_stability)
png("../stability_analysis/stability_orig.png", width=1300, height=900)
ggplot(dt_stability, aes(x=factor(params), y=1-mean_std, fill=params, group=params)) + geom_bar(stat="identity", color="black") +
theme_bw() + facet_wrap(~dataset, scales="free") + scale_y_continuous(limits=c(0.6,1), oob=rescale_none) + geom_text(aes(label=round(1-mean_std, 3)))
dev.off()
datasets <- c("bpic2012", "bpic2017", "sepsis", "traffic", "production", "hospital")
for (ds in datasets) {
p <- ggplot(subset(dt_aucs, grepl(ds, dataset)), aes(x=as.numeric(nr_events), y=auc, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
g <- ggplotly(p)
link <- plotly_POST(g, filename = paste("stability_aucs", ds, sep="_"))
}
View(dt_aucs)
datasets <- c("sepsis")
for (ds in datasets) {
p <- ggplot(subset(dt_aucs, grepl(ds, dataset)), aes(x=as.numeric(nr_events), y=auc, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
g <- ggplotly(p)
link <- plotly_POST(g, filename = paste("stability_aucs", ds, sep="_"))
}
for (ds in datasets) {
p <- ggplot(subset(dt_aucs, grepl(ds, dataset)), aes(x=as.numeric(nr_events), y=auc, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
g <- ggplotly(p)
}
g
setwd("../stability_analysis/")
# AUCS
betas <- c(0.1, 0.25, 0.5, 0.75, 0.9)
smoothed_aucs <- data.frame()
for (beta in betas) {
result_files <- list.files(".", paste("aucs.*", as.character(beta), sep=""))
for (filename in result_files) {
tmp <- read.table(filename, sep=";", header=T, na.strings=c("None"))
tmp$beta <- beta
smoothed_aucs <- rbind(smoothed_aucs, tmp)
}
}
tmp <- read.table("../stability_analysis/aucs_orig.csv", sep=";", header=T)
tmp$beta <- 0
smoothed_aucs <- rbind(smoothed_aucs, tmp)
smoothed_aucs <- subset(smoothed_aucs, dataset != "production" | nr_events != 17)
head(smoothed_aucs)
smoothed_aucs$auc <- as.numeric(smoothed_aucs$auc)
smoothed_aucs$weighted_auc <- smoothed_aucs$auc * smoothed_aucs$count
agg_aucs <- ddply(smoothed_aucs, .(dataset, params, cls, beta), summarize, avg_auc=sum(weighted_auc)/sum(count)) # weigh by number of samples for each nr_events!!!!
head(agg_aucs)
png("../stability_analysis/aucs_all.png", width=1300, height=900)
ggplot(agg_aucs, aes(x=beta, y=avg_auc, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
dev.off()
# Stability
betas <- c(0.1, 0.25, 0.5, 0.75, 0.9)
smoothed_stds <- data.frame()
for (beta in betas) {
result_files <- list.files(".", paste("instability.*", as.character(beta), sep=""))
for (filename in result_files) {
tmp <- read.table(filename, sep=";", header=T, na.strings=c("None"))
tmp$beta <- beta
smoothed_stds <- rbind(smoothed_stds, tmp)
}
}
tmp <- read.table("../stability_analysis/instability_orig.csv", sep=";", header=T)
tmp$beta <- 0
smoothed_stds <- rbind(smoothed_stds, tmp)
head(smoothed_stds)
ggplot(subset(smoothed_stds, beta==0.9), aes(x=factor(params), y=mean_std, fill=params, group=params)) + geom_bar(stat="identity", color="black") + theme_bw() + facet_wrap(~dataset, scales="free")
png("../stability_analysis/stability_all.png", width=1300, height=900)
ggplot(subset(smoothed_stds), aes(x=beta, y=1-mean_std, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
dev.off()
ds <- "sepsis_cases_1"
ds <- "bpic2012_declined"
ds <- "sepsis_cases_2"
ggplot(subset(smoothed_aucs, dataset==ds) , aes(x=as.numeric(nr_events), y=as.numeric(auc), color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~beta, scales="free")
png("../stability_analysis/aucs_smoothed.png", width=1300, height=900)
ggplot(subset(smoothed_aucs, beta==0.9) , aes(x=as.numeric(nr_events), y=as.numeric(auc), color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
dev.off()
# merged
dt_merged <- merge(agg_aucs, smoothed_stds, by=c("dataset", "params", "cls", "beta"))
head(dt_merged)
png("../stability_analysis/stability_vs_auc.png", width=1300, height=900)
ggplot(dt_merged , aes(y=avg_auc, x=1-mean_std, color=params)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~dataset, scales="free")
dev.off()
# max AUC and stability reached with each method
max_aucs <- ddply(agg_aucs, .(dataset, params), summarize, max_auc=max(avg_auc))
max_aucs_casted <- cast(max_aucs, dataset~params)
stargazer(max_aucs_casted, summary=FALSE)
smoothed_stds$stability <- 1 - smoothed_stds$mean_std
max_stabilities <- ddply(smoothed_stds, .(dataset, params), summarize, max_auc=max(stability))
max_stabilities_casted <- cast(max_stabilities, dataset~params)
stargazer(max_stabilities_casted, summary=FALSE)
max_stabilities_casted
max_aucs_casted
?stargazer
View(data)
install.packages(c("data.table", "quantreg"))
install.packages("TSA")
library(TSA)
?TSA
?arimax
data(airmiles)
plot(airmiles)
acf(diff(diff(window(log(airmiles),end=c(2001,8)),12)),lag.max=48,main='')
plot(log(airmiles),ylab='Log(airmiles)',xlab='Year', main='')
air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),
period=12),
xtransf=data.frame(I911=1*(seq(airmiles)==69), I911=1*(seq(airmiles)==69)),
transfer=list(c(0,0),c(1,0)),
xreg=data.frame(Dec96=1*(seq(airmiles)==12),
Jan97=1*(seq(airmiles)==13),Dec02=1*(seq(airmiles)==84)),method='ML')
View(air.m1)
predict(air.m1,airmiles)
xtransf=data.frame(I911=1*(seq(airmiles)==69), I911=1*(seq(airmiles)==69))
View(xtransf)
set.seed(1)
library(lubridate)
index <- ISOdatetime(2010,1,1,0,0,0)+1:8759*60*60
index
month <- month(index)
hour <- hour(index)
usage <- 1000+10*rnorm(length(index))-25*(month-6)^2-(hour-12)^2
usage <- ts(usage,frequency=24)
plot(usage)
#Create monthly dummies.  Add other xvars to this matrix
xreg <- model.matrix(~as.factor(month))[,2:12]
colnames(xreg) <- c('Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')
View(xreg)
#Fit a model
library(forecast)
install.packages("forecast")
#Fit a model
library(forecast)
model <- Arima(usage, order=c(0,0,0), seasonal=list(order=c(1,0,0), period=24), xreg=xreg)
plot(usage)
lines(fitted(model),col=2)
fitted(model)
#Benchmark against other models
model2 <- tslm(usage~as.factor(month)+as.factor(hour))
model3 <- tslm(usage~as.factor(month))
model4 <- rep(mean(usage),length(usage))
#Compare the 4 models
library(plyr) #for rbind.fill
ACC <- rbind.fill(  data.frame(t(accuracy(model))),
data.frame(t(accuracy(model2))),
data.frame(t(accuracy(model3))),
data.frame(t(accuracy(model4,usage)))
)
ACC <- round(ACC,2)
ACC <- cbind(Type=c('Arima','LM1','Monthly Mean','Mean'),ACC)
ACC[order(ACC$MAE),]
View(ACC)
install.packages("glue")
set.seed(1)
library(lubridate)
index <- ISOdatetime(2010,1,1,0,0,0)+1:8759*60*60
month <- month(index)
hour <- hour(index)
usage <- 1000+10*rnorm(length(index))-25*(month-6)^2-(hour-12)^2
usage <- ts(usage,frequency=24)
#Create monthly dummies.  Add other xvars to this matrix
xreg <- model.matrix(~as.factor(month))[,2:12]
colnames(xreg) <- c('Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')
#Fit a model
library(forecast)
model <- Arima(usage, order=c(0,0,0), seasonal=list(order=c(1,0,0), period=24), xreg=xreg)
plot(usage)
lines(fitted(model),col=2)
#Benchmark against other models
model2 <- tslm(usage~as.factor(month)+as.factor(hour))
model3 <- tslm(usage~as.factor(month))
model4 <- rep(mean(usage),length(usage))
#Compare the 4 models
library(plyr) #for rbind.fill
ACC <- rbind.fill(  data.frame(t(accuracy(model))),
data.frame(t(accuracy(model2))),
data.frame(t(accuracy(model3))),
data.frame(t(accuracy(model4,usage)))
)
ACC <- round(ACC,2)
ACC <- cbind(Type=c('Arima','LM1','Monthly Mean','Mean'),ACC)
ACC[order(ACC$MAE),]
library(TSA)
library(forecast)
data(airmiles)
air.m1<-arimax(log(airmiles),order=c(0,0,1),
xtransf=data.frame(I911=1*(seq(airmiles)==69)),
transfer=list(c(1,0))
)
air.m1
log(airmiles)
xtransf=data.frame(I911=1*(seq(airmiles)==69))
View(xtransf)
m
air.m1
tf<-filter(1*(seq(1:(length(airmiles)+5))==69),filter=0.5521330,method='recursive',side=1)*(-0.4936508)
tf
?filter
forecast.arima<-Arima(log(airmiles),order=c(0,0,1),xreg=tf[1:(length(tf)-5)])
forecast.arima
predict(forecast.arima,n.ahead = 5, newxreg=tf[114:length(tf)])
View(air.m1)
View(air.m1)
plot(airmiles)
airmiles
predict(forecast.arima,n.ahead = 5, newxreg=tf[114:length(tf)])
log(airmiles)
predict(forecast.arima,n.ahead = 5, newxreg=tf[114:length(tf)])
xreg=tf[1:(length(tf)-5)]
xreg
tf[1:(length(tf)-5)]
plot(tf)
plot(airmiles)
library(caret)
?caret::train()
remove.packages("RMongo", lib="~/R/x86_64-pc-linux-gnu-library/3.4")
library(rpart)
?rpart
?rpart.control
install.packages(c("glue", "lazyeval", "robustbase", "withr"))
install.packages(c("lubridate", "openssl", "rlang", "tidyselect"))
install.packages(c("flexdashboard", "h2o", "yaml"))
setwd("/home/coderus/Temp/git/new-flow-analysis/results/viz/Set2/detailed/SPN/")
install.packages(c("lme4", "rlang"))
result_files <- list.files()[grep(paste("^validation_FA2_(?=.*\\.csv)", sep=''), list.files(), perl=TRUE)]
result_files <- list.files()[grep(paste("^predictionResults_(?=.*\\.csv)", sep=''), list.files(), perl=TRUE)]
library(readr)
predictionResults_gspn_BPI2012O <- read_delim("predictionResults_gspn_BPI2012O.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(predictionResults_gspn_BPI2012O)
data = read.csv(filename,header = TRUE,sep = ";")
data=predictionResults_gspn_BPI2012O
strsplit(filename,"_gspn")[[1]][1]
filename = result_files[1]
strsplit(filename,"_gspn")[[1]][1]
strsplit(filename,"_gspn")[[1]][2]
strsplit(filename,"gspn_")[[1]][2]
datasetname = strsplit(filename,"gspn_")[[1]][2]
strsplit(datasetname,".")[[1]]
datasetname
strsplit(datasetname,".")
strsplit(datasetname,".csv")
strsplit(datasetname,".csv")[[1]]
df <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df) = c("dataset","method","cls","nr_events","metric","score","nr_cases")
dataset = strsplit(datasetname,".csv")[[1]]
resu\
result_files
if(dataset == "BPI2012A") max_prefix_length=7
if(dataset == "BPI2012O") max_prefix_length=4
if(dataset == "BPI2012W") max_prefix_length=10
if(dataset == "BPI2012W_no_dup") max_prefix_length=10
if(dataset == "CreditRequirement") max_prefix_length=7
if(dataset == "helpdesk") max_prefix_length=4
if(dataset == "hospital_billing_977") max_prefix_length=6
if(dataset == "minit_invoice_10") max_prefix_length=20
if(dataset == "traffic_fines_139") max_prefix_length=8
View(df)
df <- data.frame(matrix(ncol = 7, nrow = max_prefix_length-1))
colnames(df) = c("dataset","method","cls","nr_events","metric","score","nr_cases")
df$dataset = dataset
df$method = "Rogge-Solti"
df$nr_events = 2:max_prefix_length
df$cls = "SPN"
df <- data.frame(matrix(ncol = 7, nrow = max_prefix_length-1))
colnames(df) = c("dataset","method","cls","nr_events","metric","score","nr_cases")
df$dataset = dataset
df$method = "Rogge-Solti"
df$cls = "SPN"
nr_events = 2:max_prefix_length
nr_events
data = read.csv(filename,header = TRUE,sep = ";")
datasetname = strsplit(filename,"gspn_")[[1]][2]
dataset = strsplit(datasetname,".csv")[[1]]
if(dataset == "BPI2012A") max_prefix_length=7
if(dataset == "BPI2012O") max_prefix_length=4
if(dataset == "BPI2012W") max_prefix_length=10
if(dataset == "BPI2012W_no_dup") max_prefix_length=10
if(dataset == "CreditRequirement") max_prefix_length=7
if(dataset == "helpdesk") max_prefix_length=4
if(dataset == "hospital_billing_977") max_prefix_length=6
if(dataset == "minit_invoice_10") max_prefix_length=20
if(dataset == "traffic_fines_139") max_prefix_length=8
df <- data.frame(matrix(ncol = 7, nrow = max_prefix_length-1))
colnames(df) = c("dataset","method","cls","nr_events","metric","score","nr_cases")
df$dataset = dataset
df$method = "Rogge-Solti"
df$cls = "SPN"
nr_events = 2:max_prefix_length
mean(data$Error.Pnetconstrained..1)
mean(data$Error.Pnetconstrained..5)
mean(data$Error.Pnetconstrained..5,na.rm = TRUE)
mean(data$Error.Pnetconstrained..4,na.rm = TRUE)
mean(data$Error.Pnetconstrained..4,na.rm = TRUE)/1000
pref = "Error.Pnetconstrained..4"
mean(data$pref,na.rm = TRUE)/1000
mean(data$Error.Pnetconstrained..4,na.rm = TRUE)/1000
mean(data$spintf("Error.Pnetconstrained..%s",4),na.rm = TRUE)/1000
names(data)
grep("Error..Pnet.constrained", names(data), value = F)
grep("Error.Pnetconstrained", names(data), value = F)
columns_to_use = grep("Error.Pnetconstrained", names(data), value = F)
filename
grep("Iteration", names(data), value = F)
sum(grep("Iteration", names(data), value = F))
length(grep("Iteration", names(data), value = F))
len(grep("Iteration", names(data), value = F))
min(8,98)
max_prefix_length
max_prefix_length = min(max_prefix_length, length(grep("Iteration", names(data), value = F)))
max_prefix_length
mean(data[,columns_to_use[2]],na.rm = TRUE)/1000
mean(data$Error.Pnetconstrained..1,na.rm = TRUE)/1000
pref_len=2
mean(data[,columns_to_use[pref_len]],na.rm = TRUE)/1000 # make seconds
for (pref_len in nr_events) {
df$nr_events[pref_len-1] = pref_len
#mean(data[,columns_to_use[pref_len]],na.rm = TRUE)/1000 # make seconds
}
df$metric = "mae
""
"
df$metric = "mae"
for (pref_len in nr_events) {
df$nr_events[pref_len-1] = pref_len
df$score[pref_len-1] = mean(data[,columns_to_use[pref_len]],na.rm = TRUE)/1000 # make seconds
}
nr_events
nr_events = 2:max_prefix_length
for (pref_len in nr_events) {
df$nr_events[pref_len-1] = pref_len
df$score[pref_len-1] = mean(data[,columns_to_use[pref_len]],na.rm = TRUE)/1000 # make seconds
}
df <- data.frame(matrix(ncol = 7, nrow = max_prefix_length-1))
colnames(df) = c("dataset","method","cls","nr_events","metric","score","nr_cases")
df$dataset = dataset
df$method = "Rogge-Solti"
df$cls = "SPN"
df$metric = "mae"
nr_events = 2:max_prefix_length
columns_to_use = grep("Error.Pnetconstrained", names(data), value = F)
for (pref_len in nr_events) {
df$nr_events[pref_len-1] = pref_len
df$score[pref_len-1] = mean(data[,columns_to_use[pref_len]],na.rm = TRUE)/1000 # make seconds
}
mean(data$Error.Pnetconstrained..4,na.rm = TRUE)/1000
sum(data[,columns_to_use[pref_len]] >= 0,na.rm = TRUE)
for (pref_len in nr_events) {
df$nr_events[pref_len-1] = pref_len
df$score[pref_len-1] = mean(data[,columns_to_use[pref_len]],na.rm = TRUE)/1000 # make seconds
df$nr_cases[pref_len-1] = sum(data[,columns_to_use[pref_len]] >= 0,na.rm = TRUE)
}
write.csv(df,file = sprintf("../../validation_SPN_%s.csv", dataset))
write.csv(df,file = sprintf("../../validation_SPN_%s.csv", dataset), row.names = FALSE)
write.csv(df,file = sprintf("../../validation_SPN_%s.csv", dataset), row.names = FALSE, quote = FALSE)
result_files <- list.files()[grep(paste("^predictionResults_(?=.*\\.csv)", sep=''), list.files(), perl=TRUE)]
for (filename in result_files) {
data = read.csv(filename,header = TRUE,sep = ";")
datasetname = strsplit(filename,"gspn_")[[1]][2]
dataset = strsplit(datasetname,".csv")[[1]]
if(dataset == "BPI2012A") max_prefix_length=7
if(dataset == "BPI2012O") max_prefix_length=4
if(dataset == "BPI2012W") max_prefix_length=10
if(dataset == "BPI2012W_no_dup") max_prefix_length=10
if(dataset == "CreditRequirement") max_prefix_length=7
if(dataset == "helpdesk") max_prefix_length=4
if(dataset == "hospital_billing_977") max_prefix_length=6
if(dataset == "minit_invoice_10") max_prefix_length=20
if(dataset == "traffic_fines_139") max_prefix_length=8
max_prefix_length = min(max_prefix_length, length(grep("Iteration", names(data), value = F))) # in case we have less prefixes in the result file than in FA
df <- data.frame(matrix(ncol = 7, nrow = max_prefix_length-1))
colnames(df) = c("dataset","method","cls","nr_events","metric","score","nr_cases")
df$dataset = dataset
df$method = "Rogge-Solti"
df$cls = "SPN"
df$metric = "mae"
nr_events = 2:max_prefix_length
columns_to_use = grep("Error.Pnetconstrained", names(data), value = F)
for (pref_len in nr_events) {
df$nr_events[pref_len-1] = pref_len
df$score[pref_len-1] = mean(data[,columns_to_use[pref_len]],na.rm = TRUE)/1000 # make seconds
df$nr_cases[pref_len-1] = sum(data[,columns_to_use[pref_len]] >= 0,na.rm = TRUE)
}
write.csv(df,file = sprintf("../../validation_SPN_%s.csv", dataset), row.names = FALSE, quote = FALSE)
}
result_files
columns_to_use
columns_to_use_short_prefixes = columns_to_use[2:max_prefix_length]
errors_short_prefixes = c()
for (iteration in columns_to_use_short_prefixes){
errors_short_prefixes=c(errors_short_prefixes,data[,iteration])
}
mean(errors_short_prefixes,na.rm = TRUE)/(1000*60*60*24)
setwd("~/Temp/git/new-flow-analysis/results/viz/Set2")
